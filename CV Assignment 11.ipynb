{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc75af1-1b1b-4667-9f05-4463d5595f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What do REGION PROPOSALS entail?\n",
    "\n",
    "# Ans:\n",
    "# Region proposals refer to the process of generating potential bounding boxes or regions in an image that are likely to contain objects of\n",
    "# interest. These proposals serve as candidate regions for further analysis and are used in object detection and localization tasks.\n",
    "# Region proposal methods aim to identify regions that are likely to contain objects based on various criteria, such as objectness scores \n",
    "# or the presence of salient image features. These proposals help narrow down the search space for object detection algorithms, improving\n",
    "# both efficiency and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc6e0aa-8345-4d21-9169-19cfa5210f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. What do you mean by NON-MAXIMUM SUPPRESSION? (NMS)\n",
    "\n",
    "# Ans:\n",
    "# Non-maximum suppression (NMS) is a technique used in object detection to eliminate redundant bounding box proposals. After generating \n",
    "# multiple region proposals, NMS removes overlapping or redundant bounding boxes by keeping only the one with the highest confidence score. \n",
    "# It compares the intersection-over-union (IOU) overlap between the bounding boxes and applies a threshold to determine which boxes \n",
    "# to keep and which to discard. NMS helps to eliminate duplicate detections and refine the final set of bounding boxes, improving the \n",
    "# accuracy of object detection systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5580dc98-0277-4aee-817c-6895e5a22ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. What exactly is mAP?\n",
    "\n",
    "# Ans:\n",
    "# mAP stands for mean Average Precision, and it is a popular evaluation metric used in object detection tasks. It measures the performance\n",
    "# of an object detection model by calculating the average precision across multiple object classes. The average precision is computed for\n",
    "# each class based on precision-recall curves, which depict the trade-off between precision (the accuracy of the positive predictions) \n",
    "# and recall (the fraction of true positives identified). The mean Average Precision (mAP) is then calculated by taking the average of \n",
    "# the individual average precision values for all classes. mAP provides a comprehensive measure of the overall performance of an object \n",
    "# detection model across different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26a889b2-42b3-44bc-9920-e5e24ceb68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. What is a frames per secondÂ (FPS)?\n",
    "\n",
    "# Ans:\n",
    "# Frames per second (FPS) is a unit of measurement used to quantify the rate at which consecutive images (frames) are displayed or\n",
    "# processed in a video or animation. It represents the number of frames displayed or processed in one second. Higher FPS values indicate\n",
    "# smoother and more fluid motion, while lower FPS values can result in choppier or less smooth motion. FPS is an important metric in areas\n",
    "# such as video playback, gaming, and computer vision applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30721a4b-36d7-4f82-9996-3856eac6189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. What is an IOU (INTERSECTION OVER UNION)?\n",
    "\n",
    "# Ans:\n",
    "# Intersection over Union (IOU) is a metric used to measure the overlap or similarity between two bounding boxes or regions. It is\n",
    "# commonly used in object detection and evaluation tasks. IOU is calculated by dividing the area of intersection between the two regions\n",
    "# by the area of their union. The IOU value ranges from 0 to 1, where a value of 1 indicates perfect overlap and a value of 0 indicates\n",
    "# no overlap at all. IOU is often used as a criterion for comparing the accuracy of predicted bounding boxes with ground truth annotations\n",
    "# in object detection tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "287586d1-a38d-4eef-8932-54b454a569f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Describe the PRECISION-RECALL CURVE (PR CURVE)\n",
    "\n",
    "# Ans:\n",
    "# The Precision-Recall (PR) curve is a graphical representation of the trade-off between precision and recall for a binary classification \n",
    "# model. Precision measures the accuracy of positive predictions, while recall measures the fraction of true positives identified. \n",
    "# The PR curve plots precision against recall at various classification thresholds. Higher precision indicates fewer false positives, \n",
    "# while higher recall indicates fewer false negatives. The PR curve helps assess the model's performance across different thresholds \n",
    "# and provides insights into the trade-off between precision and recall. The area under the PR curve (AUPR) is often used as an \n",
    "# evaluation metric, with higher values indicating better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8c60401-ee2c-4489-bfe6-837162cdac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. What is the term &quot;selective search&quot;?\n",
    "\n",
    "# Ans:\n",
    "# Selective search is an object proposal algorithm used in computer vision for generating potential regions of interest in an image. \n",
    "# It aims to identify regions that are likely to contain objects by employing a hierarchical segmentation approach. Selective search \n",
    "# combines low-level image features, such as color, texture, and shape, to generate region proposals at multiple scales and levels of \n",
    "# abstraction. This method helps reduce the search space for object detection and recognition tasks by providing a set of candidate\n",
    "# regions for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1222b16e-5f9a-49fe-91e4-3bccddcce487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Describe the R-CNN model&#39;s four components.\n",
    "\n",
    "# Ans:\n",
    "# Region Proposal: Selective search or a similar method is used to generate potential object region proposals in the input image.\n",
    "\n",
    "# CNN Feature Extraction: Each region proposal is passed through a convolutional neural network (CNN) to extract features.\n",
    "\n",
    "# Region-wise Classification: The extracted features are fed into a set of fully connected layers to classify each region proposal\n",
    "# into different object classes.\n",
    "\n",
    "# Bounding Box Regression: Another set of fully connected layers predicts the precise bounding box coordinates for each object region\n",
    "# proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08561959-e47a-405f-a8c1-79a97cd3d16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. What exactly is the Localization Module?\n",
    "\n",
    "# Ans:\n",
    "# The Localization Module in object detection models refers to the component responsible for predicting the precise bounding box \n",
    "# coordinates for detected objects. It is typically a set of fully connected layers that take the extracted features from the region \n",
    "# proposal and output the coordinates of the object's bounding box, including its top-left and bottom-right coordinates or its center\n",
    "# coordinates along with width and height. The Localization Module helps accurately localize and position the detected objects within \n",
    "# the image, enabling precise object detection and localization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "533610a2-feec-4a41-8877-60321777e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. What are the R-CNN DISADVANTAGES?\n",
    "\n",
    "# Ans:\n",
    "# Slow training and inference: R-CNN is computationally expensive as it involves processing a large number of region proposals \n",
    "# individually, leading to slower training and inference times compared to other object detection models.\n",
    "\n",
    "# High memory consumption: The need to store and process a large number of region proposals and their corresponding feature vectors \n",
    "# requires significant memory resources.\n",
    "\n",
    "# Inflexibility in real-time applications: R-CNN's slower inference speed makes it less suitable for real-time applications that\n",
    "# require fast and responsive object detection.\n",
    "\n",
    "# Lack of end-to-end training: R-CNN consists of multiple stages and requires pre-training the region proposal network (RPN) and the\n",
    "# CNN separately, which can be less efficient and more complex compared to end-to-end training approaches.\n",
    "\n",
    "# Difficulty in handling overlapping objects: R-CNN can struggle with accurately detecting and localizing overlapping objects since \n",
    "# each region proposal is processed independently without considering the context of neighboring objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca8eca3-2b63-404a-996a-f3d04e9d12e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
