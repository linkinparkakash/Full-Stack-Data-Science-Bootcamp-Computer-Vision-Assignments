{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4b8a556-3ea8-4b08-a6ba-54b5e5a22a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What is the COVARIATE SHIFT Issue, and how does it affect you?\n",
    "\n",
    "# Ans:\n",
    "# Covariate shift is a phenomenon in machine learning where the distribution of the input features (covariates) changes between the \n",
    "# training and testing phases. It can negatively impact model performance because the model is trained on one distribution but tested \n",
    "# on a different distribution. The shift in the input distribution can lead to a mismatch between the training and testing data, \n",
    "# causing the model to make incorrect predictions. To address covariate shift, techniques such as domain adaptation, data reweighting,\n",
    "# or feature normalization can be applied to align the distributions and improve model generalization on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93d9404-93cf-4fe5-8249-fce7e3594588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. What is the process of BATCH NORMALIZATION?\n",
    "\n",
    "# Ans:\n",
    "# Batch normalization is a technique used in deep neural networks to normalize the inputs of each layer. It involves calculating the \n",
    "# mean and standard deviation of the activations within a mini-batch during training and then normalizing the activations based on \n",
    "# these statistics. This normalization helps alleviate the internal covariate shift problem, stabilizes the learning process, and \n",
    "# accelerates convergence. Additionally, batch normalization introduces learnable parameters (scale and shift) that allow the \n",
    "# network to adapt the normalized values to the specific needs of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13dcc917-9aba-43ec-8982-d67b1904ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Using our own terms and diagrams, explain LENET ARCHITECTURE.\n",
    "\n",
    "# Ans:\n",
    "# LeNet architecture is a convolutional neural network (CNN) architecture designed by Yann LeCun for handwritten digit recognition. \n",
    "# It consists of seven layers, including convolutional layers, pooling layers, and fully connected layers.\n",
    "\n",
    "# Input\n",
    "#   |\n",
    "# Convolution (6 filters, kernel size: 5x5)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Average Pooling (2x2, stride: 2)\n",
    "#   |\n",
    "# Convolution (16 filters, kernel size: 5x5)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Average Pooling (2x2, stride: 2)\n",
    "#   |\n",
    "# Flatten\n",
    "#   |\n",
    "# Fully Connected (120 units)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Fully Connected (84 units)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Output (10 units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbfd346d-f351-465f-a220-a8eb15015027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Using our own terms and diagrams, explain ALEXNET ARCHITECTURE.\n",
    "\n",
    "# Ans:\n",
    "# AlexNet is a deep convolutional neural network (CNN) architecture designed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton. \n",
    "# It achieved a breakthrough in image classification accuracy in the ImageNet Large-Scale Visual Recognition Challenge in 2012.\n",
    "\n",
    "# Input\n",
    "#   |\n",
    "# Convolution (96 filters, kernel size: 11x11, stride: 4)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Max Pooling (3x3, stride: 2)\n",
    "#   |\n",
    "# Convolution (256 filters, kernel size: 5x5, padding: 2)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Max Pooling (3x3, stride: 2)\n",
    "#   |\n",
    "# Convolution (384 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Convolution (384 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Convolution (256 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Max Pooling (3x3, stride: 2)\n",
    "#   |\n",
    "# Flatten\n",
    "#   |\n",
    "# Fully Connected (4096 units)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Fully Connected (4096 units)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Output (1000 units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5adc0cb5-801e-42d6-a010-324b25fd9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Describe the vanishing gradient problem.\n",
    "\n",
    "# Ans:\n",
    "# The vanishing gradient problem refers to the issue in deep neural networks where the gradients used to update the weights\n",
    "# during backpropagation diminish significantly as they propagate backward through the layers. As a result, the early layers of the \n",
    "# network receive very small gradient updates, leading to slow convergence or even preventing the network from learning effectively.\n",
    "# This problem is particularly prominent in deep networks with many layers and activation functions that saturate, such as the sigmoid \n",
    "# function. It hinders the network's ability to learn complex dependencies and is often mitigated using techniques like weight\n",
    "# initialization, non-saturating activation functions (e.g., ReLU), and normalization methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aacf810-d8c9-4282-b2be-1c30eb8b6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. What is NORMALIZATION OF LOCAL RESPONSE?\n",
    "\n",
    "# Ans:\n",
    "# Normalization of local response, also known as local response normalization (LRN), is a technique used in convolutional neural\n",
    "# networks (CNNs) to enhance the response of neurons and provide local contrast normalization. It involves normalizing the activation \n",
    "# of each neuron based on its neighboring activations within the same feature map. This normalization helps to highlight the most active\n",
    "# neurons and suppress the less active ones, promoting more robust and discriminative feature representations. LRN is typically applied \n",
    "# after the activation function in CNN architectures. However, it has become less commonly used in recent years, as other normalization \n",
    "# techniques like batch normalization have gained popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7725adc1-4525-474e-a291-8c1611a3c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. In AlexNet, what WEIGHT REGULARIZATION was used?\n",
    "\n",
    "# Ans:\n",
    "# In AlexNet, the weight regularization technique used is L2 regularization, also known as weight decay. L2 regularization adds a \n",
    "# penalty term to the loss function during training, which discourages large weights in the network. This helps prevent overfitting by \n",
    "# promoting smaller and more generalized weight values. The L2 regularization term is calculated as the sum of the squares of all weights \n",
    "# in the network, multiplied by a regularization parameter or weight decay coefficient. The regularization term is then added to the \n",
    "# original loss function, and during training, the network aims to minimize both the original loss and the regularization term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "537e5a7a-4030-4ea9-b750-27d258e519e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Using our own terms and diagrams, explain VGGNET ARCHITECTURE.\n",
    "\n",
    "# Ans:\n",
    "# VGGNet is a convolutional neural network (CNN) architecture developed by the Visual Geometry Group (VGG) at the University of Oxford.\n",
    "# It is known for its simplicity and depth.\n",
    "\n",
    "# Input\n",
    "#   |\n",
    "# Convolution (64 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Convolution (64 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Max Pooling (2x2, stride: 2)\n",
    "#   |\n",
    "# Convolution (128 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Convolution (128 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Max Pooling (2x2, stride: 2)\n",
    "#   |\n",
    "# Convolution (256 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Convolution (256 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Convolution (256 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Max Pooling (2x2, stride: 2)\n",
    "#   |\n",
    "# Convolution (512 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Convolution (512 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Convolution (512 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Max Pooling (2x2, stride: 2)\n",
    "#   |\n",
    "# Convolution (512 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Convolution (512 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Convolution (512 filters, kernel size: 3x3, padding: 1)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Max Pooling (2x2, stride: 2)\n",
    "#   |\n",
    "# Fully Connected (4096 units)\n",
    "#   |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Fully Connected (4096 units)\n",
    "#  |\n",
    "# ReLU Activation\n",
    "#   |\n",
    "# Output (1000 units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9d9f206-7508-4994-8f82-db8e0ca90803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Describe VGGNET CONFIGURATIONS.\n",
    "\n",
    "# Ans:\n",
    "# VGGNet offers different configurations with varying depths, denoted as VGG16 and VGG19, based on the number of convolutional layers. \n",
    "# VGG16 consists of 16 convolutional layers, while VGG19 has 19 convolutional layers. Both configurations share a similar overall\n",
    "# architecture, but the deeper VGG19 model provides a more expressive feature representation at the cost of increased computational\n",
    "# complexity. These configurations have been widely used as benchmarks for image classification tasks and have shown strong performance \n",
    "# on various datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "419d41a6-01b4-4212-bed9-052321ca63e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. What regularization methods are used in VGGNET to prevent overfitting?\n",
    "\n",
    "# Ans:\n",
    "# In VGGNet, two main regularization methods are used to prevent overfitting: dropout and weight decay (L2 regularization). \n",
    "# Dropout randomly sets a fraction of the neuron activations to zero during training, forcing the network to learn redundant\n",
    "# representations and reducing interdependence among neurons. Weight decay, also known as L2 regularization, adds a penalty term to\n",
    "# the loss function that discourages large weight values, promoting smaller and more generalized weights. These regularization techniques\n",
    "# help VGGNet generalize better to unseen data and improve its ability to handle overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e928e-249c-439c-8c3d-cfeaffa561d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
